---
title: "ChainLadder Package in Action"
author: "Andy Merlino"
date: "Tuesday, November 18, 2014"
output: pdf_document
---

### Purpose

The `ChainLadder` package includes methods for projecting insurance loss reserves.  For more information on the `ChainLadder` package please see the [package vignette](http://cran.r-project.org/web/packages/ChainLadder/vignettes/ChainLadder.pdf).  This document will compare `ChainLadder` projections to actual historic losses to measure the accuracy of the different `ChainLadder` reserving methods.

### Data

The CAS website provides historic U.S. insurance loss data accross 6 different lines of business and many different companies.  The data includes complete triangles from origin years 1988 through 1997.  We will use data from origin years 1988 through 1997 evaluated as of 1997 to run the `ChainLadder` projections.  The data will be projected out to the 10th development year and compared to actual loss data at that time.  The CAS data sets include data from the following lines of business:

* Workers' Compensation
* Private Passenger Auto
* Commercial Auto
* Medical Malpractice
* Other Liability
* Product liability

For more information on the data see the [CAS webpage](http://www.casact.org/research/index.cfm?fa=loss_reserves_data).

```{r packages_data, message = FALSE}
library(ChainLadder) # install.packages("ChainLadder")

library(dplyr) # for data manipulation
library(pander) # for creating tables

# package I created to store CAS data
library(casdata) # devtools::install_github("merlinoa/casdata")

# pander options
panderOptions('table.split.table', Inf)
panderOptions('table.alignment.default', 'right')
```

### A little data cleaning

A good portion of the companies in the data sets are missing loss information for a portion of the origin years (e.g for workers compensation 70 out of 132 do not have loss information for all origin years at all development years).  We are going to remove companies with missing or very small loss amounts.

```{r data_cleaning}
# Combine data sets into a list 
data_sets <- list(wkcomp, ppauto, prodliab, comauto, medmal, othliab)

# identify unique companies in each data set that have missing data
# I also had some trouble with companies that had very small losses, so I decided
# to remove all companies with cumulative paid losses less than 100 
# at any observation in the data set.
id_missing_data <- lapply(data_sets, function(x) unique(x$GRCODE[x[, 7] <= 100]))

# remove companies that have missing data
for (i in seq_along(data_sets)) {
  data_sets[[i]] <- data_sets[[i]][-which(data_sets[[i]]$GRCODE %in% 
                                            id_missing_data[[i]]), ]
}
```

### Workers' Compensation

First we need to make the triangles.  We will look at the paid triangles first.

```{r wc_paid_tri}
# isolate workers' compensation data
wkcomp_clean <- data_sets[[1]]

# find unique GRCODEs for looping
wkcomp_id <- unique(wkcomp_clean$GRCODE)

# create triangles for each company using `ChainLadder` package
paid_tri <- vector("list", length(wkcomp_id))
for (i in seq_along(wkcomp_id)) {
  paid_tri[[i]] <- as.triangle(wkcomp_clean[wkcomp_clean$GRCODE == wkcomp_id[i] & 
                                      wkcomp_clean$AccidentYear + 
                                      wkcomp_clean$DevelopmentLag < 1999, ], 
                               origin = "AccidentYear", 
                               dev = "DevelopmentLag", 
                               value = "CumPaidLoss_D")
}
```


### Mack Method

```{r wc_mack, warning = FALSE}
# run mack model as provided in ChainLadder package
wc_mack <- lapply(paid_tri, MackChainLadder, est.sigma = "Mack")

# select relevant value for comparison to actual loss values
mack_smry <- vector("list", length(wc_mack))
for (i in seq_along(wc_mack)) {
  mack_smry[[i]] <- summary(wc_mack[[i]])[[2]]$Totals[c(1, 3:5)]
}

mack_smry <- as.data.frame(t(as.data.frame(mack_smry)))
rownames(mack_smry) <- NULL
mack_smry <- data.frame(wkcomp_id, mack_smry)
names(mack_smry) <- c("GRCODE", "Latest", "Ultimate", "IBNR", "Mack S.E.")

# compare Mack projections to actual losses
actual_paid <- filter(wkcomp_clean, DevelopmentLag == 10) %>%
  group_by(GRCODE) %>%
  summarise(actual_ultimate = sum(CumPaidLoss_D))

mack_smry <- left_join(mack_smry, actual_paid, by = "GRCODE")

mack_smry_f <- data.frame(mack_smry[, 1, drop = FALSE], format(round(mack_smry[2:6], 0), 
                                                               big.mark = ","))
pander(mack_smry_f, justify = "right")
```

Let's check to see how well the Mack projection stacks up against the actual historical loss data.  Quickly we can check the percentage of actual ultimate losses that fall within one Mack S.E. of the projected ultimate losses.

```{r}
ifelse (mack_smry[, 5] > abs(mack_smry$actual_ultimate - mack_smry$ultimate),
        0, 1) 
```